#  **2023-2 머신러닝(학과 전공 과정) 팀프로젝트(Kaggle Competition)**

## 🧑‍🤝‍🧑 **팀원**
- **박원우**
- **이재원**
- **김상욱**

## 📅 **진행 시기**
- **2023년 2학기**

## 💡 **주제**
- **설문조사 패널 정보를 통한 설문 전송 시 응답 여부 예측(분류)**

##  📌 **데이터셋**
- 패널정보/응답여부(train/test)
  
## 📌 **주요 분석 내용**

### - **Main Idea**
- 응답여부를 예측하는 것인데, 각각 ID별 응답률을 계산할때 타겟을 활용하니, 이외 파생변수는
  최대한 타겟 활용을 배제하자. (과적합 최소화)
  
### - **결측치 처리**
- 처음에 결측치 확인
- 컬럼들이 전체적으로 결측치의 비율이 높아, 전부 삭제하게 되면 정보의 손실 과다로 판단
- 결측값 비율이 30프로 이하인 컬럼만 사용
- 수치형은 평균값, 범주형은 최빈값으로 대체

### - **Feature Engineering**
- 기존 data column 조합 추가 파생 변수 생성
- 성별,지역,패널타입 조합을 통한 고유값 매핑
- 유저아이디, 설문아이디 별 응답률 피쳐 생성
- 수치형 변수간 사칙연산을 통한 의미있는 통계량값 생성
- 이외 여러 파생변수는 생략

### - **Encoding & Scaling**
- 범주형 변수에 OrdinalEncoder 활용
- 수치형 변수에 StandardScaling 적용

### - **Feature Selection**
- Feature Importance 임계치 설정하여 활용 feature의 개수 조정
- 다수의 실험을 통해 모델별로 다른 임계치, 최적 threshold 설정
  
### - **Modeling**
- XGB, Catboost, LGBM, RandomForest Classifier 각각 모델별 튜닝, 학습 후 평가
- 개별모델 성능 비교하여 모델별 가중치 설정해 Soft voting 진행, 임계치 설정을 통해 이진 분류

<br/>

## 📝 **분석 결과 및 결론**
- 평가지표 : Accuracy
- 약 86.54프로 모델 정확도 획득, private rank 분반 1등을 달성할 수 있었습니다.
- 각각 모델 학습을 시킬때, Feature Seletion 과정에서 기여도 계산해서 각 모델별 train set을 만들었는데 특정 모델에
  다른 train set을 넣는게 성능을 더 좋을때가 있었습니다. 꼭 해당 모형을 기반으로 피쳐 기여도를 산출했다고 해서 최적 SET이 나오는 것은 아니다.(발견)
- 범주형 피쳐들을 활용해 파생변수를 만들때 단순 문자열 간 연결도 유의미한 결과를 만들어낼 때가 많다.(발견)
